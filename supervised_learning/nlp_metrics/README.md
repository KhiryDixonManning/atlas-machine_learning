This folder contains files created to practice implementing Bi-Lingual Evaluation Understudy (BLEU) for evaluating Natural Language Processing (NLP) models. Each file represents a different method of calculating BLEU scores, with a focus on unigram, n-gram, and cumulative BLEU scores. The files are designed to be used as a starting point for implementing these methods in Python